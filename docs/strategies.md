This file describes the strategies (Federated Optimization Algorithms) which are avalaible in this framework.

1. `fedavg`: Federated Averaging (FedAvg) [McMahan et al., 2016] strategy Paper: https://arxiv.org/abs/1602.05629
2. `fedyogi` : Adaptive Federated Optimization using Yogi (FedYogi) [Reddi et al., 2020]
strategy. Paper: https://arxiv.org/abs/2003.00295
3. `fedadagrad` : Adaptive Federated Optimization using Adagrad (FedAdagrad) [Reddi et al.,
2020] strategy. Paper: https://arxiv.org/abs/2003.00295
4. `fedavgm` : Federated Averaging with Momentum (FedAvgM) [Hsu et al., 2019] strategy. Paper: https://arxiv.org/pdf/1909.06335.pdf
5. `fedex` : (NIPS 2021) Federated hyperparameter tuning: Challenges, baselines, and connections to weight-sharing Paper: https://proceedings.neurips.cc/paper/2021/hash/a0205b87490c847182672e8d371e9948-Abstract.html